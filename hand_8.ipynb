{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import svgwrite\n",
    "from IPython.display import SVG, display\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FakeArgParse():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "args = FakeArgParse()\n",
    "\n",
    "args.train = True\n",
    "\n",
    "args.rnn_size = 10\n",
    "args.tsteps = 50\n",
    "args.nmixtures = 5\n",
    "\n",
    "args.kmixtures = 1\n",
    "args.alphabet = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "args.tsteps_per_ascii = 25\n",
    "\n",
    "args.batch_size = 1\n",
    "args.nepochs = 250\n",
    "args.dropout = 0.8\n",
    "args.nbatches = 500\n",
    "\n",
    "args.grad_clip = 10\n",
    "args.learning_rate = 1e-4\n",
    "args.lr_decay = 0.95\n",
    "\n",
    "args.data_scale = 20\n",
    "args.data_dir = './data'\n",
    "args.log_dir = './output'\n",
    "args.save_path = './output/model.ckpt'\n",
    "args.save_every = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, args, bias=0, infer=False):\n",
    "        self.args = args\n",
    "        self.char_vec_len = len(args.alphabet) + 1\n",
    "        self.train = args.train\n",
    "        self.dropout = args.dropout\n",
    "        self.ascii_steps = args.tsteps/args.tsteps_per_ascii\n",
    "        if infer:\n",
    "            args.batch_size = 1\n",
    "            args.seq_length = 1\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self.input_data = tf.placeholder(tf.float32, [None,args.tsteps,3], name='x_batch')\n",
    "        self.target_data = tf.placeholder(tf.float32, [None,args.tsteps,3], name='y_batch')\n",
    "        self.char_seq = tf.placeholder(tf.float32, [None, self.ascii_steps, self.char_vec_len], name='input_ascii')\n",
    "\n",
    "        self.graves_initializer = tf.truncated_normal_initializer(mean=0., stddev=.075, seed=None, dtype=tf.float32)\n",
    "        self.window_b_initializer = tf.truncated_normal_initializer(mean=-3.0, stddev=.25, seed=None, dtype=tf.float32)\n",
    "\n",
    "        NOUT = 1 + args.nmixtures * 6\n",
    "\n",
    "        W = tf.get_variable(\"W\", [args.rnn_size,NOUT], initializer=self.graves_initializer)\n",
    "        b = tf.get_variable(\"b\", [NOUT], initializer=self.graves_initializer)\n",
    "        W_attn = tf.get_variable(\"W_attn\", [args.rnn_size,args.kmixtures*3], initializer=self.graves_initializer)\n",
    "        b_attn = tf.get_variable(\"b_attn\", [args.kmixtures*3], initializer=self.window_b_initializer)\n",
    "\n",
    "        cell_func = tf.contrib.rnn.LSTMCell # could be GRUCell or RNNCell\n",
    "        def lstm_cell():\n",
    "            if (self.train and self.dropout < 1): # training mode\n",
    "                return tf.contrib.rnn.DropoutWrapper(cell_func(args.rnn_size, state_is_tuple=True, initializer=self.graves_initializer), output_keep_prob = self.dropout)\n",
    "            else:\n",
    "                return cell_func(args.rnn_size, state_is_tuple=True, initializer=self.graves_initializer)\n",
    "\n",
    "        self.cell0 = lstm_cell()\n",
    "        self.istate_cell0 = self.cell0.zero_state(args.batch_size, tf.float32)\n",
    "\n",
    "        inputs = [tf.squeeze(input_, [1]) for input_ in tf.split(self.input_data, args.tsteps, 1)]\n",
    "\n",
    "        outs_cell0, self.fstate_cell0 = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, self.istate_cell0, self.cell0, loop_function=None, scope='cell0')\n",
    "        \n",
    "        def get_phi(alpha, beta, kappa):\n",
    "            u = np.arange(self.ascii_steps)\n",
    "            kappa_term = tf.square(tf.subtract(kappa,u))\n",
    "            exp_term = tf.multiply(-beta,kappa_term)\n",
    "            phi_k = tf.multiply(alpha, tf.exp(exp_term))\n",
    "            phi = tf.reduce_sum(phi_k,1, keep_dims=True)\n",
    "            return phi\n",
    "        \n",
    "        self.init_kappa = tf.placeholder(dtype=tf.float32, shape=[None, args.kmixtures, 1]) \n",
    "        prev_kappa = self.init_kappa\n",
    "\n",
    "        for t in range(args.tsteps):\n",
    "            attn = tf.matmul(outs_cell0[t], W_attn) + b_attn\n",
    "            attn_k = tf.exp(tf.reshape(attn, [-1, 3*args.kmixtures,1]))\n",
    "            [alpha, beta, kappa] = tf.split(attn_k, 3, axis=1)\n",
    "            kappa = kappa + prev_kappa\n",
    "            phi = get_phi(alpha, beta, kappa)\n",
    "            c = tf.matmul(phi,self.char_seq)\n",
    "            c = tf.squeeze(c, [1])\n",
    "            outs_cell0[t] = tf.concat([outs_cell0[t], c, inputs[t]],1)\n",
    "            prev_kappa = kappa\n",
    "\n",
    "        self.window = c\n",
    "        self.phi = phi\n",
    "        #print self.output_1.shape\n",
    "\n",
    "        self.new_kappa = prev_kappa\n",
    "\n",
    "        \n",
    "        self.cell1 = lstm_cell()\n",
    "        self.istate_cell1 = self.cell1.zero_state(args.batch_size, tf.float32)\n",
    "        outs_cell1, self.fstate_cell1 = tf.contrib.legacy_seq2seq.rnn_decoder(outs_cell0, self.istate_cell1, self.cell1, loop_function=None, scope='cell1')\n",
    "\n",
    "        self.cell2 = lstm_cell()\n",
    "        self.istate_cell2 = self.cell2.zero_state(args.batch_size, tf.float32)\n",
    "        outs_cell2, self.fstate_cell2 = tf.contrib.legacy_seq2seq.rnn_decoder(outs_cell1, self.istate_cell2, self.cell2, loop_function=None, scope='cell2')\n",
    "\n",
    "        states_series = tf.reshape(tf.concat(outs_cell2,1), [-1, args.rnn_size])\n",
    "        #self.state_out = tf.identity(current_state, name='state_out')\n",
    "        output = tf.matmul(states_series, W) + b\n",
    "        #[x1, x2, eos] = tf.split(axis=1, num_or_size_splits=3, value=flat_data)\n",
    "        #eos = tf.sigmoid(eos)\n",
    "\n",
    "        flat_target_data = tf.reshape(self.target_data,[-1, 3])\n",
    "        [x1_data, x2_data, eos_data] = tf.split(axis=1, num_or_size_splits=3, value=flat_target_data)\n",
    "\n",
    "        #x1_loss = tf.losses.mean_squared_error(x1_data, x1)\n",
    "        #x2_loss = tf.losses.mean_squared_error(x2_data, x2)\n",
    "        #eos_loss = tf.losses.softmax_cross_entropy(eos_data, eos)\n",
    "        \n",
    "        def tf_2d_normal(x1, x2, mu1, mu2, s1, s2, rho):\n",
    "            # eq # 24 and 25 of http://arxiv.org/abs/1308.0850\n",
    "            norm1 = tf.subtract(x1, mu1)\n",
    "            norm2 = tf.subtract(x2, mu2)\n",
    "            s1s2 = tf.multiply(s1, s2)\n",
    "            z = tf.square(tf.div(norm1, s1))+tf.square(tf.div(norm2, s2))-2*tf.div(tf.multiply(rho, tf.multiply(norm1, norm2)), s1s2)\n",
    "            negRho = 1-tf.square(rho)\n",
    "            result = tf.exp(tf.div(-z,2*negRho))\n",
    "            denom = 2*np.pi*tf.multiply(s1s2, tf.sqrt(negRho))\n",
    "            result = tf.div(result, denom)\n",
    "            return result\n",
    "\n",
    "        def get_lossfunc(z_pi, z_mu1, z_mu2, z_sigma1, z_sigma2, z_corr, z_eos, x1_data, x2_data, eos_data):\n",
    "            result0 = tf_2d_normal(x1_data, x2_data, z_mu1, z_mu2, z_sigma1, z_sigma2, z_corr)\n",
    "            # implementing eq # 26 of http://arxiv.org/abs/1308.0850\n",
    "            epsilon = 1e-20\n",
    "            result1 = tf.multiply(result0, z_pi)\n",
    "            result1 = tf.reduce_sum(result1, 1, keep_dims=True)\n",
    "            result1 = -tf.log(tf.maximum(result1, 1e-20)) # at the beginning, some errors are exactly zero.\n",
    "\n",
    "            result2 = tf.multiply(z_eos, eos_data) + tf.multiply(1-z_eos, 1-eos_data)\n",
    "            result2 = -tf.log(result2)\n",
    "\n",
    "            result = result1 + result2\n",
    "            return tf.reduce_sum(result)\n",
    "\n",
    "        # below is where we need to do MDN splitting of distribution params\n",
    "        def get_mixture_coef(output):\n",
    "            # returns the tf slices containing mdn dist params\n",
    "            # ie, eq 18 -> 23 of http://arxiv.org/abs/1308.0850\n",
    "            z = output\n",
    "            z_eos = z[:, 0:1]\n",
    "            z_pi, z_mu1, z_mu2, z_sigma1, z_sigma2, z_corr = tf.split(axis=1, num_or_size_splits=6, value=z[:, 1:])\n",
    "\n",
    "            # process output z's into MDN paramters\n",
    "\n",
    "            # end of stroke signal\n",
    "            z_eos = tf.sigmoid(z_eos) # should be negated, but doesn't matter.\n",
    "\n",
    "            b=0 # BIAS\n",
    "\n",
    "            # softmax all the pi's:\n",
    "            max_pi = tf.reduce_max(z_pi, 1, keep_dims=True)\n",
    "            z_pi = tf.subtract(z_pi, max_pi)\n",
    "            z_pi = tf.exp(z_pi*(1+b))\n",
    "            normalize_pi = tf.reciprocal(tf.reduce_sum(z_pi, 1, keep_dims=True))\n",
    "            z_pi = tf.multiply(normalize_pi, z_pi)\n",
    "\n",
    "            # exponentiate the sigmas and also make corr between -1 and 1.\n",
    "            z_sigma1 = tf.exp(z_sigma1-b)\n",
    "            z_sigma2 = tf.exp(z_sigma2-b)\n",
    "            z_corr = tf.tanh(z_corr)\n",
    "\n",
    "            return [z_pi, z_mu1, z_mu2, z_sigma1, z_sigma2, z_corr, z_eos]\n",
    "\n",
    "\n",
    "        [o_pi, o_mu1, o_mu2, o_sigma1, o_sigma2, o_corr, o_eos] = get_mixture_coef(output)\n",
    "\n",
    "        self.pi = o_pi\n",
    "        self.mu1 = o_mu1\n",
    "        self.mu2 = o_mu2\n",
    "        self.sigma1 = o_sigma1\n",
    "        self.sigma2 = o_sigma2\n",
    "        self.corr = o_corr\n",
    "        self.eos = o_eos\n",
    "\n",
    "        lossfunc = get_lossfunc(o_pi, o_mu1, o_mu2, o_sigma1, o_sigma2, o_corr, o_eos, x1_data, x2_data, eos_data)\n",
    "        self.cost = lossfunc / (args.batch_size * args.tsteps)\n",
    "\n",
    "        self.learning_rate = tf.Variable(0.0, trainable=False)\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), 10.)\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "        \n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(args):\n",
    "    logger = Logger(args) # make logging utility\n",
    "    logger.write(\"\\nTRAINING MODE...\")\n",
    "    logger.write(\"{}\\n\".format(args))\n",
    "    logger.write(\"loading data...\")\n",
    "    data_loader = DataLoader(args, logger=logger)\n",
    "\n",
    "    logger.write(\"building model...\")\n",
    "    model = Model(args)\n",
    "\n",
    "    v_x, v_y, v_s, v_c = data_loader.validation_data()\n",
    "    valid_inputs = {model.input_data: v_x, model.target_data: v_y, model.char_seq: v_c}\n",
    "\n",
    "    logger.write(\"training...\")\n",
    "    for e in range(args.nepochs):\n",
    "        model.sess.run(tf.assign(model.learning_rate, args.learning_rate * (args.lr_decay ** e)))\n",
    "        logger.write(\"learning rate: {}\".format(model.learning_rate.eval()))\n",
    "\n",
    "        c0, c1, c2 = model.istate_cell0.c.eval(), model.istate_cell1.c.eval(), model.istate_cell2.c.eval()\n",
    "        h0, h1, h2 = model.istate_cell0.h.eval(), model.istate_cell1.h.eval(), model.istate_cell2.h.eval()\n",
    "        kappa = np.zeros((args.batch_size, args.kmixtures, 1))\n",
    "\n",
    "        for b in range(args.nbatches):\n",
    "\n",
    "            i = e * args.nbatches + b\n",
    "\n",
    "            if i % args.save_every == 0 and (i > 0):\n",
    "                model.saver.save(model.sess, args.save_path) ; logger.write('SAVED MODEL')\n",
    "                with open(args.log_dir + '/checkpoint', \"w\") as raw:\n",
    "                    raw.write('model_checkpoint_path: \"model\"\\nall_model_checkpoint_paths: \"model\"')\n",
    "\n",
    "\n",
    "            start = time.time()\n",
    "            x, y, s, c = data_loader.next_batch()\n",
    "\n",
    "            feed = {model.input_data: x, model.target_data: y, model.char_seq: c, model.init_kappa: kappa, \\\n",
    "              model.istate_cell0.c: c0, model.istate_cell1.c: c1, model.istate_cell2.c: c2, \\\n",
    "              model.istate_cell0.h: h0, model.istate_cell1.h: h1, model.istate_cell2.h: h2}\n",
    "\n",
    "            [train_loss, _] = model.sess.run([model.cost, model.train_op], feed)\n",
    "\n",
    "            end = time.time()\n",
    "            if i % 10 is 0: logger.write(\"{}/{}, loss = {:.3f}, time = {:.3f}\" \\\n",
    "                .format(i, args.nepochs * args.nbatches, train_loss, end - start) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING MODE...\n",
      "<__main__.FakeArgParse instance at 0x7f9ef50d26c8>\n",
      "\n",
      "loading data...\n",
      "\tloaded dataset:\n",
      "\t\t11321 train individual data points\n",
      "\t\t595 valid individual data points\n",
      "\t\t11321 batches\n",
      "building model...\n",
      "training...\n",
      "learning rate: 9.99999974738e-05\n",
      "0/125000, loss = 2.736, time = 2.361\n",
      "10/125000, loss = 3.552, time = 0.017\n",
      "20/125000, loss = 5.789, time = 0.016\n",
      "30/125000, loss = 3.133, time = 0.017\n",
      "40/125000, loss = 4.344, time = 0.016\n",
      "SAVED MODEL\n",
      "50/125000, loss = 3.669, time = 0.024\n",
      "60/125000, loss = 2.902, time = 0.017\n",
      "70/125000, loss = 5.352, time = 0.017\n",
      "80/125000, loss = 3.999, time = 0.018\n",
      "90/125000, loss = 3.985, time = 0.017\n",
      "SAVED MODEL\n",
      "100/125000, loss = 5.684, time = 0.025\n",
      "110/125000, loss = 7.173, time = 0.017\n",
      "120/125000, loss = 4.206, time = 0.017\n",
      "130/125000, loss = 5.167, time = 0.017\n",
      "140/125000, loss = 3.173, time = 0.017\n",
      "SAVED MODEL\n",
      "150/125000, loss = 4.503, time = 0.026\n",
      "160/125000, loss = 4.167, time = 0.019\n",
      "170/125000, loss = 4.523, time = 0.017\n",
      "180/125000, loss = 3.421, time = 0.016\n",
      "190/125000, loss = 5.026, time = 0.017\n",
      "SAVED MODEL\n",
      "200/125000, loss = 3.939, time = 0.027\n",
      "210/125000, loss = 7.679, time = 0.017\n",
      "220/125000, loss = 3.111, time = 0.017\n",
      "230/125000, loss = 3.992, time = 0.017\n",
      "240/125000, loss = 5.615, time = 0.017\n",
      "SAVED MODEL\n",
      "250/125000, loss = 5.834, time = 0.024\n",
      "260/125000, loss = 5.936, time = 0.017\n",
      "270/125000, loss = 4.157, time = 0.017\n",
      "280/125000, loss = 2.919, time = 0.016\n",
      "290/125000, loss = 3.572, time = 0.017\n",
      "SAVED MODEL\n",
      "300/125000, loss = 5.010, time = 0.025\n",
      "310/125000, loss = 4.983, time = 0.016\n",
      "320/125000, loss = 5.104, time = 0.017\n",
      "330/125000, loss = 4.389, time = 0.017\n",
      "340/125000, loss = 4.079, time = 0.016\n",
      "SAVED MODEL\n",
      "350/125000, loss = 3.217, time = 0.025\n",
      "360/125000, loss = 3.849, time = 0.017\n",
      "370/125000, loss = 3.410, time = 0.017\n",
      "380/125000, loss = 4.901, time = 0.017\n",
      "390/125000, loss = 3.181, time = 0.017\n",
      "SAVED MODEL\n",
      "400/125000, loss = 3.876, time = 0.025\n",
      "410/125000, loss = 6.438, time = 0.017\n",
      "420/125000, loss = 3.698, time = 0.017\n",
      "430/125000, loss = 4.331, time = 0.017\n",
      "440/125000, loss = 3.410, time = 0.017\n",
      "SAVED MODEL\n",
      "450/125000, loss = 4.095, time = 0.018\n",
      "460/125000, loss = 3.259, time = 0.016\n",
      "470/125000, loss = 2.563, time = 0.017\n",
      "480/125000, loss = 2.931, time = 0.017\n",
      "490/125000, loss = 3.310, time = 0.017\n",
      "learning rate: 9.50000030571e-05\n",
      "SAVED MODEL\n",
      "500/125000, loss = 4.207, time = 0.028\n",
      "510/125000, loss = 3.296, time = 0.017\n",
      "520/125000, loss = 2.924, time = 0.016\n",
      "530/125000, loss = 2.797, time = 0.017\n",
      "540/125000, loss = 2.855, time = 0.017\n",
      "SAVED MODEL\n",
      "550/125000, loss = 3.478, time = 0.026\n",
      "560/125000, loss = 4.164, time = 0.014\n",
      "570/125000, loss = 3.576, time = 0.015\n",
      "580/125000, loss = 3.368, time = 0.015\n",
      "590/125000, loss = 5.899, time = 0.015\n",
      "SAVED MODEL\n",
      "600/125000, loss = 4.507, time = 0.026\n",
      "610/125000, loss = 3.666, time = 0.015\n",
      "620/125000, loss = 4.904, time = 0.014\n",
      "630/125000, loss = 3.749, time = 0.015\n",
      "640/125000, loss = 2.630, time = 0.014\n",
      "SAVED MODEL\n",
      "650/125000, loss = 3.891, time = 0.027\n",
      "660/125000, loss = 6.402, time = 0.015\n",
      "670/125000, loss = 3.585, time = 0.014\n",
      "680/125000, loss = 5.497, time = 0.015\n",
      "690/125000, loss = 2.689, time = 0.015\n",
      "SAVED MODEL\n",
      "700/125000, loss = 3.081, time = 0.026\n",
      "710/125000, loss = 4.479, time = 0.015\n",
      "720/125000, loss = 3.067, time = 0.015\n",
      "730/125000, loss = 3.727, time = 0.016\n",
      "740/125000, loss = 5.176, time = 0.015\n",
      "SAVED MODEL\n",
      "750/125000, loss = 3.267, time = 0.027\n",
      "760/125000, loss = 4.551, time = 0.015\n",
      "770/125000, loss = 2.544, time = 0.014\n",
      "780/125000, loss = 3.247, time = 0.015\n",
      "790/125000, loss = 2.813, time = 0.015\n",
      "SAVED MODEL\n",
      "800/125000, loss = 3.332, time = 0.025\n",
      "810/125000, loss = 2.076, time = 0.015\n",
      "820/125000, loss = 2.691, time = 0.015\n",
      "830/125000, loss = 2.978, time = 0.015\n",
      "840/125000, loss = 3.303, time = 0.014\n",
      "SAVED MODEL\n",
      "850/125000, loss = 3.541, time = 0.025\n",
      "860/125000, loss = 3.615, time = 0.014\n",
      "870/125000, loss = 3.187, time = 0.015\n",
      "880/125000, loss = 4.301, time = 0.015\n",
      "890/125000, loss = 2.352, time = 0.015\n",
      "SAVED MODEL\n",
      "900/125000, loss = 2.740, time = 0.026\n",
      "910/125000, loss = 3.258, time = 0.015\n",
      "920/125000, loss = 2.415, time = 0.015\n",
      "930/125000, loss = 3.631, time = 0.015\n",
      "940/125000, loss = 4.090, time = 0.015\n",
      "SAVED MODEL\n",
      "950/125000, loss = 2.869, time = 0.027\n",
      "960/125000, loss = 3.949, time = 0.016\n",
      "970/125000, loss = 2.533, time = 0.015\n",
      "980/125000, loss = 2.358, time = 0.015\n",
      "990/125000, loss = 2.638, time = 0.014\n",
      "learning rate: 9.0250003268e-05\n",
      "SAVED MODEL\n",
      "1000/125000, loss = 2.258, time = 0.037\n",
      "1010/125000, loss = 2.632, time = 0.015\n",
      "1020/125000, loss = 4.660, time = 0.015\n",
      "1030/125000, loss = 3.078, time = 0.021\n",
      "1040/125000, loss = 3.777, time = 0.014\n",
      "SAVED MODEL\n",
      "1050/125000, loss = 3.846, time = 0.026\n",
      "1060/125000, loss = 3.074, time = 0.015\n",
      "1070/125000, loss = 4.159, time = 0.014\n",
      "1080/125000, loss = 2.233, time = 0.014\n",
      "1090/125000, loss = 5.411, time = 0.015\n",
      "SAVED MODEL\n",
      "1100/125000, loss = 3.897, time = 0.024\n",
      "1110/125000, loss = 4.772, time = 0.015\n",
      "1120/125000, loss = 4.416, time = 0.015\n",
      "1130/125000, loss = 3.034, time = 0.015\n",
      "1140/125000, loss = 2.017, time = 0.015\n",
      "SAVED MODEL\n",
      "1150/125000, loss = 2.522, time = 0.026\n",
      "1160/125000, loss = 4.384, time = 0.015\n",
      "1170/125000, loss = 5.187, time = 0.015\n",
      "1180/125000, loss = 2.806, time = 0.015\n",
      "1190/125000, loss = 2.461, time = 0.015\n",
      "SAVED MODEL\n",
      "1200/125000, loss = 2.863, time = 0.027\n",
      "1210/125000, loss = 3.961, time = 0.015\n",
      "1220/125000, loss = 3.000, time = 0.015\n",
      "1230/125000, loss = 3.064, time = 0.014\n",
      "1240/125000, loss = 2.799, time = 0.018\n",
      "SAVED MODEL\n",
      "1250/125000, loss = 2.705, time = 0.025\n",
      "1260/125000, loss = 2.978, time = 0.014\n",
      "1270/125000, loss = 2.714, time = 0.015\n",
      "1280/125000, loss = 2.171, time = 0.015\n",
      "1290/125000, loss = 3.405, time = 0.017\n",
      "SAVED MODEL\n",
      "1300/125000, loss = 3.696, time = 0.028\n",
      "1310/125000, loss = 5.022, time = 0.014\n",
      "1320/125000, loss = 3.502, time = 0.014\n",
      "1330/125000, loss = 2.333, time = 0.015\n",
      "1340/125000, loss = 2.445, time = 0.015\n",
      "SAVED MODEL\n",
      "1350/125000, loss = 3.716, time = 0.022\n",
      "1360/125000, loss = 3.870, time = 0.014\n",
      "1370/125000, loss = 2.588, time = 0.014\n",
      "1380/125000, loss = 3.053, time = 0.015\n",
      "1390/125000, loss = 3.997, time = 0.014\n",
      "SAVED MODEL\n",
      "1400/125000, loss = 4.339, time = 0.025\n",
      "1410/125000, loss = 3.875, time = 0.015\n",
      "1420/125000, loss = 3.046, time = 0.015\n",
      "1430/125000, loss = 3.889, time = 0.015\n",
      "1440/125000, loss = 2.068, time = 0.015\n",
      "SAVED MODEL\n",
      "1450/125000, loss = 3.715, time = 0.025\n",
      "1460/125000, loss = 3.394, time = 0.015\n",
      "1470/125000, loss = 2.942, time = 0.015\n",
      "1480/125000, loss = 2.969, time = 0.014\n",
      "1490/125000, loss = 3.213, time = 0.014\n",
      "learning rate: 8.57374980114e-05\n",
      "SAVED MODEL\n",
      "1500/125000, loss = 3.112, time = 0.030\n",
      "1510/125000, loss = 2.541, time = 0.015\n",
      "1520/125000, loss = 2.061, time = 0.015\n",
      "1530/125000, loss = 3.390, time = 0.014\n",
      "1540/125000, loss = 2.164, time = 0.015\n",
      "SAVED MODEL\n",
      "1550/125000, loss = 2.476, time = 0.025\n",
      "1560/125000, loss = 3.002, time = 0.015\n",
      "1570/125000, loss = 4.035, time = 0.015\n",
      "1580/125000, loss = 3.646, time = 0.014\n",
      "1590/125000, loss = 3.227, time = 0.014\n",
      "SAVED MODEL\n",
      "1600/125000, loss = 3.837, time = 0.017\n",
      "1610/125000, loss = 2.783, time = 0.015\n",
      "1620/125000, loss = 3.287, time = 0.015\n",
      "1630/125000, loss = 2.355, time = 0.014\n",
      "1640/125000, loss = 2.618, time = 0.014\n",
      "SAVED MODEL\n",
      "1650/125000, loss = 3.281, time = 0.023\n",
      "1660/125000, loss = 3.595, time = 0.015\n",
      "1670/125000, loss = 2.985, time = 0.015\n",
      "1680/125000, loss = 2.923, time = 0.014\n",
      "1690/125000, loss = 2.364, time = 0.015\n",
      "SAVED MODEL\n",
      "1700/125000, loss = 3.318, time = 0.027\n",
      "1710/125000, loss = 3.014, time = 0.015\n",
      "1720/125000, loss = 4.948, time = 0.014\n",
      "1730/125000, loss = 3.462, time = 0.015\n",
      "1740/125000, loss = 4.079, time = 0.016\n",
      "SAVED MODEL\n",
      "1750/125000, loss = 4.257, time = 0.026\n",
      "1760/125000, loss = 2.720, time = 0.014\n",
      "1770/125000, loss = 3.169, time = 0.015\n",
      "1780/125000, loss = 3.545, time = 0.014\n",
      "1790/125000, loss = 2.847, time = 0.014\n",
      "SAVED MODEL\n",
      "1800/125000, loss = 2.068, time = 0.026\n",
      "1810/125000, loss = 2.130, time = 0.015\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c3ce05502f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-795914445cb7>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar_seq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_kappa\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkappa\u001b[0m\u001b[1;33m,\u001b[0m               \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m,\u001b[0m               \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mh1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mistate_cell2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mh2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;33m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gaurav/Desktop/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gaurav/Desktop/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gaurav/Desktop/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/gaurav/Desktop/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gaurav/Desktop/assignment1/.env/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
